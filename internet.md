# Internet

- Introduction

## Introduction

Though it began as a military experiment and spent its adolescence as a sandbox for academics and eccentrics, in less than a decade just before the new millenium the worldwide network of computer networks (the internet) matured into hihgly diversified, financially important community of computer users and information vendors. 

The internet is a worlwide collection of computer networks - a network of networks - sharing digital information via a common set of networking and software protocols. Networks are not new to computers. What makes internet unique is its worlwide collection of digital telecommunication links that share a common set of computer-network technologies, protocols and applications. 

The common and now quite familiar programs people use toc communicate and distribute their work over the internet have also found their way into private and semiprivate networks. These so-called intranets and extranets use the same software, applications, and networking protocols as the internet. But unlike the internet, intranets are private networks with access restrictred to members of the institution. Likewise, extranets restrict access but use intenret to provide services to members. The internet, on the other hand, seemingly has no restrictions. 

The internet began in the late 1960s as an experiments in the design of robust computer networks. The goal was to construct a network of computers that could withstand the loss of several machines without compromising the ability of the remaining ones to communicate. Funding came from the U.S.Department of Defence which had a vested interest in building information networks that could withstand nuclear attack. The resulting network was a marvelous technical success, but it was limited in size and scope. For the most part, only defence contractors and academic institutions could gain access to what was then known as the ARPAnet (Advanced Reseach Projects Agency Network of the Department of Defence). It wasn't unitl 1993 that the internet really took off. Several crucial events led to the meteoric rise in popularity of the internet. First, in the early 1990s, businesses and individuals eager to take advantage of the ease and power of global digital communications finally pressured the largest computer networks on the mostly U.S. government-funded internet to open their systems for nearly unrestricted traffic. Unfortunately, getting connected and using the various software tools, if they were available for their computers, presented an insumountable technology barrier for most people. And most available information was plain-vanilla text about academic subjects, not neatly packaged fare that attracts users to services such as America Online. At about the same time the internet opened up for business, so physicists at CERN, the European Particle Physics Laboratory, released an authoring language and distribution system they developed for creating and sharing mulimedia-enabled, integrated eletronic documents over the internet. And so was born Hypertext Markup Language (HTML), browser software and the web. No longer did authours have to distribute their work as fragmented collections of pictures, sounds and text. HTML unified those elements. Moreover, the web's system enabled hypertext linking, whereby documents automatically reference other documents located anywhere around the world. Lif-off happened when some bright students and faculty at the National center of Supercomputing Applications (NCSA) at the Univresity of Illinois Urbana-Champaign wrote a web browser called Mosaic. Although designed primarily for viewing HTML documents, the software also had built-in tools to access the more prolific resources on the internet, such as FTP archives of software and Gopher-organized collections of documents. 

Every computer connected to the internet has a unique address: a number whose formated is defined by the internet protocol (IP), the standard that defines how messages are passed from one machine to another on the net. THe IP address is made up of four numbers, each less than 256, joined together by periods, such as 192.12.245.72. While computers deal only with numbers, people prefer names. For this reason, most computers also have names bestowed upon them. The internet is a network of networks, and is divided into groups known as domains, which are futher divided into one or more subdomains. Special computers, known as nameservers, keep tables of machine names and associated IP addresses and translate one into the other for use and for our machines. 

The internet connects two kinds of computers: servers, which serve up documents, and clietns, which retrieve and siplay documents for us humans. Things that happen on the server machine are said to be on the server side, and activities on the client machine occure on the client side. TO access and display HTML documents, we run programs called browsers on our client computers. These browser clients talk to special web servers over the internet to access, retriece and display eletronic documents. When starting up on the network, the client browser first consults a domain name system (DNS), before sending a request to that server over the internet. This request (abd th server's reply) is formatted according to the dictates of the Hypertext Transfer Protocol (HTTP) standard. A sever spends most of the time listening to the network, waiting for document requests with the server's uniques address stamped on them. Upon receipt of a request, the server verifies that the requesting browser is allowed to retrieve documents from the server and, if so, checks for the the requested document. If it fins the document, the server sends it to the browser. THe server usually logs the request, typically including the client computer's IP address, the document requested, and the time. The server might also issues special attachments known as cookies to contain additional information about requesting browser and its owner. 

Like many popular technologies, HTML started ou as an information specification used by only a few people. As more and more authors began to use the language, it became obvious that more formal means were needed to define and manage - to standardice - the language's features, making it easier for everyone to create and share documents. The World Wide Web Consortium (W3C) was formed with the charter to define the standards for HTML and, later, XHTML. Beyond HTML and XHTML, the W3C has the broader responsibility of standardizing any technology related to the Web. They manage th HTTP, Cascading Style Sheets (CSS) and Extensible Markup Language (XML) standards, as well as related standards for document addressing on the web. Even broader in reach that W3C, the Internet Engineering Task Force (IETF) is responsible for defining and managing every aspect of internet technology. The Web is just one small area under the purview of the IETF.
